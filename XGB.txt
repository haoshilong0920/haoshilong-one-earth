import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from bayes_opt import BayesianOptimization
from sklearn.metrics import classification_report
import shap
from sklearn import metrics

# 读取数据
data = pd.read_csv(r'F:\研究生\巢湖论文\新新数据\shuju.csv')
y = data.iloc[:, 0]
X = data.iloc[:, 1:]

# 划分数据集+
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义目标函数
def xgb_evaluate(max_depth, learning_rate, n_estimators, gamma, min_child_weight, subsample, colsample_bytree,
                 reg_alpha, reg_lambda):
    # 五折交叉验证
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    accuracies = []
    for train_idx, val_idx in cv.split(X_train, y_train):
        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]
        X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]
        model = XGBClassifier(objective='binary:logistic', num_class=1, max_depth=int(max_depth),
                              learning_rate=learning_rate, n_estimators=int(n_estimators), gamma=gamma,
                              min_child_weight=min_child_weight, subsample=subsample, colsample_bytree=colsample_bytree,
                              reg_alpha=reg_alpha, reg_lambda=reg_lambda, random_state=42)
        model.fit(X_train_fold, y_train_fold)
        y_pred_fold = model.predict(X_val_fold)
        accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)
        accuracies.append(accuracy_fold)
    accuracy = np.mean(accuracies)
    return accuracy

# 定义参数空间
parameter_space = {'max_depth': (3, 10),
                   'learning_rate': (0.01, 0.3),
                   'n_estimators': (10, 500),
                   'gamma': (0, 1),
                   'min_child_weight': (1, 10),
                   'subsample': (0.1, 1),
                   'colsample_bytree': (0.1, 1),
                   'reg_alpha': (0, 1),
                   'reg_lambda': (0, 1)}

# 进行贝叶斯优化
xgb_bo = BayesianOptimization(f=xgb_evaluate, pbounds=parameter_space, random_state=42)
xgb_bo.maximize(init_points=10, n_iter=20)

# 输出最优参数
best_params = xgb_bo.max['params']
for key in best_params:
    if isinstance(best_params[key], float):
        best_params[key] = round(best_params[key], 2)

best_params['n_estimators'] = int(best_params['n_estimators'])
best_params['max_depth'] = int(best_params['max_depth'])
print("Best parameters: ", best_params)

# 在测试集上进行预测
best_model = XGBClassifier(objective='binary:logistic', num_class=1, **best_params, random_state=42)
best_model.fit(X_train, y_train)

# 计算训练集准确度
y_pred_train = best_model.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)
print("Training Accuracy: ", accuracy_train)

# 输出测试集准确度
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: ", accuracy)

# 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)
confusion_matrix_result = metrics.confusion_matrix(y_pred, y_test)
print('The confusion matrix result:\n', confusion_matrix_result)
print(classification_report(y_test, y_pred))

# 获取特征重要性分数
importance = best_model.feature_importances_
for i, feature in enumerate(X.columns):
    print('Feature %s importance: %.3f' % (feature, importance[i]))


